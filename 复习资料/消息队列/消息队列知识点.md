## 1、MQ 基础

### 1、MQ 基础知识点
消息队列的核心思想是：生产者将消息发送到队列，消费者从队列中拉取或被推送消息进行处理。有 “发布-订阅” 或 “点对点” 两种模式。

消息队列有如下作用：
- 解耦：生产者和消费者无需直接通信；
- 异步：生产者发送后可立即返回，不等待消费者处理；
- 削峰填谷：突发流量可缓存在队列中，由消费者逐步处理；
- 可靠性：通过持久化、ACK、重试等机制保障消息不丢失。
- 日志处理：解耦日志采集与日志处理，解决大量日志传输的问题

一个典型的消息队列系统包含以下核心组件：

一个典型的消息队列系统包含以下核心组件：

![alt text](/复习资料/消息队列/img/image.png)

### 2、消息队列通信的模式

#### （1）点对点模式

点对点模式通常是基于**拉取或者轮询**的消息传送模型，这个模型的特点是发送到队列的消息只能被一个消费者进行处理。生产者将消息放入消息队列后，由消费者主动的去拉取消息进行消费。

点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。

**工作流程：**
- Producer 发送消息到 Queue。
- Queue 存储消息（可持久化）。
- 多个 Consumer 监听该 Queue。
- 消息被第一个可用的 Consumer 拿走，其他 Consumer 不可见。
- 消费成功后，消息从 Queue 中移除（或标记为已消费）。

**典型应用场景：**
- 订单处理系统：多个订单处理服务实例竞争消费订单消息。
- 任务分发：将计算任务分发给空闲的工作节点。

**支持的 MQ：** RabbitMQ（使用普通 Queue）、RocketMQ（集群消费模式）、ActiveMQ

![alt text](/复习资料/消息队列/img/image-1.png)


#### （2）发布订阅模式

生产者将消息放入消息队列的一个 topic 后，每个订阅该 Topic 的 Consumer Group 都会收到一份完整的消息副本。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息。

但是不同消费者，如consumer1、consumer2、consumer3由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题。假设三个消费者处理速度分别是8M/s、5M/s、2M/s，如果队列推送的速度为5M/s，则consumer3无法承受，如果队列推送的速度为2M/s，则consumer1、consumer2会出现资源的极大浪费。

~~~ txt
Producer ──► [ Topic ]
                │
                ├─► Consumer Group A ──► Consumer A1, A2 （A 组内竞争）
                │
                └─► Consumer Group B ──► Consumer B1, B2 （B 组内竞争）
~~~

**工作流程**：
- Producer 发布消息到 Topic。
- 所有订阅该 Topic 的 Consumer Group 都会收到消息。
- 每个 Group 内部，消息被分发给其中一个成员（负载均衡）。
- 不同 Group 之间互不影响。

**典型应用场景：**
- 用户注册事件：通知邮件服务、短信服务、数据分析服务等。
- 日志广播：多个系统需要监听同一类日志。

**支持的 MQ：** Kafka（核心模型）、RocketMQ（广播消费 or 多 Group 集群消费）、NATS（Subject + 多 Subscriber）、RabbitMQ（通过 Exchange + 多 Queue 绑定模拟）

![alt text](/复习资料/消息队列/img/image-2.png)

## 2、Kafka

### （1）Kafka 基础

Kafka 特性：

- **高吞吐量、低延迟**：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒
- **可扩展性**：kafka集群支持热扩展
- **持久性、可靠性**：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- **容错性**：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- **高并发**：支持数千个客户端同时读写

Kafka场景应用：

- **日志收集**：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
- **消息系统**：解耦和生产者和消费者、缓存消息等。
- **用户活动跟踪**：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- **运营指标**：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

### （2）Kafka 架构

Kafka 的架构图如下：

![alt text](/复习资料/消息队列/img/image-3.png)

各个元素的作用：

- Producer：Producer即生产者，消息的产生者，是消息的入口。

- Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等……

- Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。

- Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！

- Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。

- Message：每一条发送的消息主体。

- Consumer：消费者，即消息的消费方，是消息的出口。

- Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！

- Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。


### （3）Kafka 工作流程

#### （1）发送消息

Producer 在写入数据的时候永远的找leader，不会直接将数据写入 follower，producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的。

![alt text](/复习资料/消息队列/img/image-4.png)

#### （2）保存数据

kafka将数据保存在磁盘，可能在一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。**Kafka初始会单独开辟一块磁盘空间，顺序写入数据**（效率比随机写入高）。

**Partition 结构**：Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。

![alt text](/复习资料/消息队列/img/image-5.png)

**Message结构**：消息主要包含消息体、消息大小、offset
- offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！

- 消息大小：消息大小占用4byte，用于描述消息的大小。

- 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。

#### （3）存储策略

无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？
- 基于时间，默认配置是168小时（7天）。
- 基于大小，默认配置是1073741824。

需要注意的是，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！

#### （4）消费数据

Kafka采用的是发布订阅模式，消费者主动的去kafka集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader去拉取。

多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id，同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！！！

### （4）常见问题解析

#### （1）为什么 Kafka 多 partition 能提升吞吐量
- 生产者可并行写入多个 Partition；
- 消费者组可并行消费多个 Partition；
- 每个 Partition 的 Leader 分布在不同 Broker 上，实现 I/O 和网络负载分散；
- 副本机制保障高可用，但不直接提升吞吐。
- 同时，一个 topic 设置多个 partition 也是方便后续拓展

#### （2）Kafka 是推（Push）还是拉（Pull）

**消费者主动从 Broker 拉取数据**，如果是push模式，Broker 决定推送速率，可能压垮慢消费者。pull 模式消费者按自己处理能力拉取，天然支持背压控制。

#### （3）同一个 Partition 的数据能否被多个消费者组使用

同一个 Partition 的数据可以被任意多个消费者组独立消费！

Kafka 不会为每个消费者组复制消息，所有消费者组共享同一份日志文件（即 Partition 的 .log 文件），每个消费者组独立维护自己的消费位移（Offset），因此，增加消费者组几乎无存储开销（只多存 Offset）

#### （4）ZooKeeper 在 Kafka 中维护什么信息
- 旧版本（Kafka < 2.8）：ZooKeeper 存储元数据
- 新版本（Kafka ≥ 2.8 + KRaft 模式）：完全移除 ZooKeeper，元数据由 Kafka 自身管理。

![alt text](/复习资料/消息队列/img/image-6.png)


#### （5）生产者消费者如何找到 leader

以生产者为例：

- Producer 启动时，配置 bootstrap.servers=broker1:9092,broker2:9092；

- 连接任意一个 Broker，发送 MetadataRequest；

- 该 Broker 从 ZooKeeper（或 KRaft 元数据日志）读取元数据，返回：
    - Topic 的 Partition 列表；
    - 每个 Partition 的 Leader Broker 地址；

- Producer 缓存这些信息，后续直接向对应 Leader 发送消息。


Kafka 2.8 引入 KRaft（Kafka Raft Metadata Mode），3.x 默认推荐，完全去 ZooKeeper，元数据存储在内部 Topic __cluster_metadata，架构更简单，运维成本更低。

#### （6）消费者如何记录消费位置（Offset）

Offset 存储位置的演进：

| Kafka 版本 | Offset 存储位置 | 说明 |
|-----------|------------------|------|
| < 0.8.2 | ZooKeeper | 每个消费者组的 offset 写入 ZK 路径（如 `/consumers/group1/offsets/topic/partition`） |
| ≥ 0.8.2 | Kafka 内部 Topic：`__consumer_offsets` | 默认启用，性能更高，ZK 不再承担写压力 |


消费者向broker 提交 Offset 的方式：

**（1）自动提交**
- 配置：enable.auto.commit=true（默认）
- 行为：消费者后台定期（由 auto.commit.interval.ms 控制，默认 5 秒）自动向 Broker 提交当前消费到的 offset。
- 优点：简单，无需代码干预。
- 缺点：可能重复消费（如果消费后、提交前崩溃）。

**（2）手动提交**

配置：enable.auto.commit=false，代码中显式调用：
~~~ java
// 同步提交（阻塞直到成功）
consumer.commitSync();

// 异步提交（不阻塞）
consumer.commitAsync();
~~~
优点：可精确控制提交时机，实现“至少一次”或“恰好一次”语义。
缺点：需处理提交失败、重试等逻辑。

无论自动还是手动提交，Offset 最终都写入 Kafka 的一个内部压缩 Topic。**消费者拉取（poll）本身不提交 offset，提交 offset 是独立操作（自动后台提交 or 手动调用 commit）**

常规代码：
~~~ java
while (true) {
    // 1. 拉取消息（不提交 offset）
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

    for (ConsumerRecord<String, String> record : records) {
        // 2. 处理消息
        process(record);
    }

    // 3. 手动提交 offset（表示这些消息已成功处理）
    consumer.commitSync();  // ← 这一步才向 Broker 提交 offset
}
~~~

注意：提交的 offset = 下一条要消费的消息的位置。例如：你消费了 offset=100 的消息，提交 offset=101，表示“101 之前都处理完了”。

### （5）Kafka 如何保证数据不丢失

#### （1）生产者（Producer）端：确保消息成功写入 Kafka

风险：网络抖动、Broker 故障导致消息未写入 broker。

默认配置：
~~~ properties
acks=1          # 只需 Leader 确认（Leader 宕机且未同步 → 丢失）
retries=0       # 不重试（网络抖动直接失败）
~~~

防止消息丢失配置：
~~~ properties
# 关键三件套
acks=all                    # 要求 ISR 全部副本确认
retries=Integer.MAX_VALUE   # 无限重试（配合幂等防重复）
enable.idempotence=true     # 开启幂等，即使重试，Broker 也会去重

# 副本策略保障
replication.factor=3        # Topic 副本数 ≥3
min.insync.replicas=2       # Broker 端配置：写入至少 2 个 ISR 才算成功，如果 ISR 少于 2 个（如只剩 Leader），Broker 会拒绝写入
~~~

#### （2）Broker 端：确保持久化存储

风险点：消息未刷盘就宕机

如何确保消息持久化：
- 多副本（Replication）：数据在多个 Broker 上冗余存储

- ISR（In-Sync Replicas）：只有与 Leader 保持同步的副本才在 ISR 中，ISR指的是与 leader 节点数据同步的副本

- Unclean Leader 选举关闭	unclean.leader.election.enable=false（默认）→ 禁止非 ISR 副本当选 Leader，避免数据丢失

这里不强制刷盘，因为强制刷盘性能极差（磁盘 I/O 成瓶颈），Kafka 依赖副本机制而非单机持久化来保证可靠性。

**总结：多副本、副本数据与leader同步，不强制刷盘。**

#### （3）Consumer 端：确保消息消费后提交 offset

Consumer 端默认自动向 Kafka 提交 offset，若处理到一半宕机，Offset 已提交，消息丢失！

消费端改为**手动提交 + 先处理后提交，且确保业务处理和提交两个操作是原子性的。**

### （6）Kafka 如何防止数据重复消费

**Kafka 不保证 Exactly-Once，但提供工具让应用实现它。**

重复的根本原因：
- Producer 重试：网络超时，Broker 已写入但未返回 ACK → Producer 重发 → 重复
- 消费者重启：Offset 回退到上一次提交位置 → 重复消费
- 自动提交 Offset：提交后处理失败 → 重启后跳过消息（丢失）；处理中提交 → 重启后重复

#### （1）Producer 幂等性

配置：
~~~ properties
enable.idempotence=true
~~~

原理：每个 Producer 分配唯一 PID（Producer ID），每条消息带 Sequence Number（按 Partition 递增），Broker 维护 (PID, Partition) 的最大 Seq，收到重复 Seq → 直接丢弃。

效果：**单 Partition 内 Exactly-Once（但跨 Partition 不保证）**

#### （2）Consumer 业务幂等

无论 Kafka 是否重复，业务逻辑必须幂等。

- 数据库：落库时，数据使用唯一约束。或者处理后更新这行数据对应的状态，如支付场景，订单状态从 “CREATED” → “PAID”。

- 缓存：Redis 记录已处理 ID；

### （7）Kafka 如何解决消息积压问题

积压 = Latest Offset - Committed Offset 持续增长。

**先定位积压原因**：

- 所有 Partition Lag ：消费者整体处理慢
- 个别 Partition Lag 高：数据倾斜（如某个 key 热点）
- 消费者频繁 Rebalance：GC 停顿、心跳超时

#### （1）方案 1：扩容消费者

前提：Partition 数 ≥ 消费者数，这时扩容消费者，Partition 自动分配给新消费者，并行度提升。

#### （2）优化消费者处理逻辑

- 批量处理
- 异步处理
- 减少外部依赖耗时，如优化数据库查询（走索引）、缓存热点数据

#### （3）临时应急：跳过积压（慎用！）

积压百万条，业务允许丢弃旧数据（重置 Offset 到最新位置），积压消息永久丢失，仅用于非关键业务（如非关键业务数据）。

#### （4）限流与降级（预防积压）

- Producer 限流：使用令牌桶控制发送速率，监控 Broker 磁盘 IO，动态调整。

- Consumer 降级：非核心消息写入死信队列（DLQ），返回错误码，由上游重试。

#### （5）监控与告警

这里需要看一下监控平台是否有 Kafka 堆积的告警，然后ELK日志采集如何知道日志丢失。

参考：https://cloud.tencent.com/developer/article/2088077


## 3、RocketMQ

RocketMQ主要由四个基本组件构成：

- NameServer（命名服务器）：
  NameServer是RocketMQ网络中的注册中心和路由中心，提供轻量级服务发现和路由功能。每个Broker启动时都会在所有NameServer上注册自己的路由信息，包括当前Broker的IP地址、提供的Topic等信息。消费者和生产者通过查询NameServer来获取Topic的路由信息。

- Broker（消息代理服务器）：
  Broker是消息处理的核心节点，负责存储消息、验证和服务消息传输。RocketMQ支持多个Broker配置，可以是同步或异步复制数据以确保高可用性。Broker处理大量的数据写入操作，并支持消息的顺序和并行处理。

- Producer（生产者）：
  生产者负责发布消息到指定的Topic。RocketMQ支持多种消息发送模式，包括同步发送、异步发送和单向发送（不等待服务器响应）。

- Consumer（消费者）：
  消费者从Broker订阅消息并处理它们。RocketMQ支持**集群消费和广播消费**两种模式。在集群模式下，同一个Consumer Group中的不同Consumer实例平均分摊消息，而在广播模式下，每个Consumer实例都会接收到所有的消息。

- Topic和Queue： Topic是消息的分类，每个Topic可以分为若干个Queue。RocketMQ通过增加Queue数量来水平扩展Topic的处理能力。

RocketMQ 支持多种消息模式，包括**顺序消息、定时/延时消息和批量消息**等。此外，RocketMQ 提供了丰富的消息过滤功能，消费者可以根据Tag或者SQL92标准进行消息过滤，极大地增加了其灵活性和应用场景。

![alt text](/复习资料/消息队列/img/image-8.png)






