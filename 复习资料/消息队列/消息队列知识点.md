## 1、MQ 基础

### 1、MQ 基础知识点
消息队列的核心思想是：生产者将消息发送到队列，消费者从队列中拉取或被推送消息进行处理。有 “发布-订阅” 或 “点对点” 两种模式。

消息队列有如下作用：
- 解耦：生产者和消费者无需直接通信；
- 异步：生产者发送后可立即返回，不等待消费者处理；
- 削峰填谷：突发流量可缓存在队列中，由消费者逐步处理；
- 可靠性：通过持久化、ACK、重试等机制保障消息不丢失。
- 日志处理：解耦日志采集与日志处理，解决大量日志传输的问题

一个典型的消息队列系统包含以下核心组件：

一个典型的消息队列系统包含以下核心组件：

![alt text](/复习资料/消息队列/img/image.png)

### 2、消息队列通信的模式

#### （1）点对点模式

点对点模式通常是基于**拉取或者轮询**的消息传送模型，这个模型的特点是发送到队列的消息只能被一个消费者进行处理。生产者将消息放入消息队列后，由消费者主动的去拉取消息进行消费。

点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。

**工作流程：**
- Producer 发送消息到 Queue。
- Queue 存储消息（可持久化）。
- 多个 Consumer 监听该 Queue。
- 消息被第一个可用的 Consumer 拿走，其他 Consumer 不可见。
- 消费成功后，消息从 Queue 中移除（或标记为已消费）。

**典型应用场景：**
- 订单处理系统：多个订单处理服务实例竞争消费订单消息。
- 任务分发：将计算任务分发给空闲的工作节点。

**支持的 MQ：** RabbitMQ（使用普通 Queue）、RocketMQ（集群消费模式）、ActiveMQ

![alt text](/复习资料/消息队列/img/image-1.png)


#### （2）发布订阅模式

生产者将消息放入消息队列的一个 topic 后，每个订阅该 Topic 的 Consumer Group 都会收到一份完整的消息副本。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息。

但是不同消费者，如consumer1、consumer2、consumer3由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题。假设三个消费者处理速度分别是8M/s、5M/s、2M/s，如果队列推送的速度为5M/s，则consumer3无法承受，如果队列推送的速度为2M/s，则consumer1、consumer2会出现资源的极大浪费。

~~~ txt
Producer ──► [ Topic ]
                │
                ├─► Consumer Group A ──► Consumer A1, A2 （A 组内竞争）
                │
                └─► Consumer Group B ──► Consumer B1, B2 （B 组内竞争）
~~~

**工作流程**：
- Producer 发布消息到 Topic。
- 所有订阅该 Topic 的 Consumer Group 都会收到消息。
- 每个 Group 内部，消息被分发给其中一个成员（负载均衡）。
- 不同 Group 之间互不影响。

**典型应用场景：**
- 用户注册事件：通知邮件服务、短信服务、数据分析服务等。
- 日志广播：多个系统需要监听同一类日志。

**支持的 MQ：** Kafka（核心模型）、RocketMQ（广播消费 or 多 Group 集群消费）、NATS（Subject + 多 Subscriber）、RabbitMQ（通过 Exchange + 多 Queue 绑定模拟）

![alt text](/复习资料/消息队列/img/image-2.png)

## 2、Kafka

### （1）Kafka 基础

Kafka 特性：

- **高吞吐量、低延迟**：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒
- **可扩展性**：kafka集群支持热扩展
- **持久性、可靠性**：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- **容错性**：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- **高并发**：支持数千个客户端同时读写

Kafka场景应用：

- **日志收集**：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
- **消息系统**：解耦和生产者和消费者、缓存消息等。
- **用户活动跟踪**：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- **运营指标**：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

### （2）Kafka 架构

Kafka 的架构图如下：

![alt text](/复习资料/消息队列/img/image-3.png)

各个元素的作用：

- Producer：Producer即生产者，消息的产生者，是消息的入口。

- Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等……

- Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。

- Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！

- Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。

- Message：每一条发送的消息主体。

- Consumer：消费者，即消息的消费方，是消息的出口。

- Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！

- Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。


### （3）Kafka 工作流程

#### （1）发送消息

Producer 在写入数据的时候永远的找leader，不会直接将数据写入 follower，producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的。

![alt text](/复习资料/消息队列/img/image-4.png)

#### （2）保存数据

kafka将数据保存在磁盘，可能在一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。**Kafka初始会单独开辟一块磁盘空间，顺序写入数据**（效率比随机写入高）。

**Partition 结构**：Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。

![alt text](/复习资料/消息队列/img/image-5.png)

**Message结构**：消息主要包含消息体、消息大小、offset
- offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！

- 消息大小：消息大小占用4byte，用于描述消息的大小。

- 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。

#### （3）存储策略

无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？
- 基于时间，默认配置是168小时（7天）。
- 基于大小，默认配置是1073741824。

需要注意的是，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！

#### （4）消费数据

Kafka采用的是发布订阅模式，消费者主动的去kafka集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader去拉取。

多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id，同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！！！

### （4）常见问题解析

#### （1）为什么 Kafka 多 partition 能提升吞吐量
- 生产者可并行写入多个 Partition；
- 消费者组可并行消费多个 Partition；
- 每个 Partition 的 Leader 分布在不同 Broker 上，实现 I/O 和网络负载分散；
- 副本机制保障高可用，但不直接提升吞吐。
- 同时，一个 topic 设置多个 partition 也是方便后续拓展

#### （2）Kafka 是推（Push）还是拉（Pull）

**消费者主动从 Broker 拉取数据**，如果是push模式，Broker 决定推送速率，可能压垮慢消费者。pull 模式消费者按自己处理能力拉取，天然支持背压控制。

#### （3）同一个 Partition 的数据能否被多个消费者组使用

同一个 Partition 的数据可以被任意多个消费者组独立消费！

Kafka 不会为每个消费者组复制消息，所有消费者组共享同一份日志文件（即 Partition 的 .log 文件），每个消费者组独立维护自己的消费位移（Offset），因此，增加消费者组几乎无存储开销（只多存 Offset）

#### （4）ZooKeeper 在 Kafka 中维护什么信息
- 旧版本（Kafka < 2.8）：ZooKeeper 存储元数据
- 新版本（Kafka ≥ 2.8 + KRaft 模式）：完全移除 ZooKeeper，元数据由 Kafka 自身管理。

![alt text](/复习资料/消息队列/img/image-6.png)


#### （5）生产者消费者如何找到 leader

以生产者为例：

- Producer 启动时，配置 bootstrap.servers=broker1:9092,broker2:9092；

- 连接任意一个 Broker，发送 MetadataRequest；

- 该 Broker 从 ZooKeeper（或 KRaft 元数据日志）读取元数据，返回：
    - Topic 的 Partition 列表；
    - 每个 Partition 的 Leader Broker 地址；

- Producer 缓存这些信息，后续直接向对应 Leader 发送消息。


Kafka 2.8 引入 KRaft（Kafka Raft Metadata Mode），3.x 默认推荐，完全去 ZooKeeper，元数据存储在内部 Topic __cluster_metadata，架构更简单，运维成本更低。

#### （6）消费者如何记录消费位置（Offset）

Offset 存储位置的演进：

| Kafka 版本 | Offset 存储位置 | 说明 |
|-----------|------------------|------|
| < 0.8.2 | ZooKeeper | 每个消费者组的 offset 写入 ZK 路径（如 `/consumers/group1/offsets/topic/partition`） |
| ≥ 0.8.2 | Kafka 内部 Topic：`__consumer_offsets` | 默认启用，性能更高，ZK 不再承担写压力 |


消费者向broker 提交 Offset 的方式：

**（1）自动提交**
- 配置：enable.auto.commit=true（默认）
- 行为：消费者后台定期（由 auto.commit.interval.ms 控制，默认 5 秒）自动向 Broker 提交当前消费到的 offset。
- 优点：简单，无需代码干预。
- 缺点：可能重复消费（如果消费后、提交前崩溃）。

**（2）手动提交**

配置：enable.auto.commit=false，代码中显式调用：
~~~ java
// 同步提交（阻塞直到成功）
consumer.commitSync();

// 异步提交（不阻塞）
consumer.commitAsync();
~~~
优点：可精确控制提交时机，实现“至少一次”或“恰好一次”语义。
缺点：需处理提交失败、重试等逻辑。

无论自动还是手动提交，Offset 最终都写入 Kafka 的一个内部压缩 Topic。**消费者拉取（poll）本身不提交 offset，提交 offset 是独立操作（自动后台提交 or 手动调用 commit）**

常规代码：
~~~ java
while (true) {
    // 1. 拉取消息（不提交 offset）
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

    for (ConsumerRecord<String, String> record : records) {
        // 2. 处理消息
        process(record);
    }

    // 3. 手动提交 offset（表示这些消息已成功处理）
    consumer.commitSync();  // ← 这一步才向 Broker 提交 offset
}
~~~

注意：提交的 offset = 下一条要消费的消息的位置。例如：你消费了 offset=100 的消息，提交 offset=101，表示“101 之前都处理完了”。

### （5）Kafka 如何保证数据不丢失

#### （1）生产者（Producer）端：确保消息成功写入 Kafka

风险：网络抖动、Broker 故障导致消息未写入 broker。

默认配置：
~~~ properties
acks=1          # 只需 Leader 确认（Leader 宕机且未同步 → 丢失）
retries=0       # 不重试（网络抖动直接失败）
~~~

防止消息丢失配置：
~~~ properties
# 关键三件套
acks=all                    # 要求 ISR 全部副本确认
retries=Integer.MAX_VALUE   # 无限重试（配合幂等防重复）
enable.idempotence=true     # 开启幂等，即使重试，Broker 也会去重

# 副本策略保障
replication.factor=3        # Topic 副本数 ≥3
min.insync.replicas=2       # Broker 端配置：写入至少 2 个 ISR 才算成功，如果 ISR 少于 2 个（如只剩 Leader），Broker 会拒绝写入
~~~

**ISR（In-Sync Replicas） 是指：与 Leader 副本保持“足够同步”的 Follower 副本集合。ISR 允许一定延迟，但不能太落后。**

#### （2）Broker 端：确保持久化存储

风险点：消息未刷盘就宕机

如何确保消息持久化：
- 多副本（Replication）：数据在多个 Broker 上冗余存储

- ISR（In-Sync Replicas）：只有与 Leader 保持同步的副本才在 ISR 中，ISR指的是与 leader 节点数据同步的副本

- Unclean Leader 选举关闭	unclean.leader.election.enable=false（默认）→ 禁止非 ISR 副本当选 Leader，避免数据丢失

这里不强制刷盘，因为强制刷盘性能极差（磁盘 I/O 成瓶颈），Kafka 依赖副本机制而非单机持久化来保证可靠性。

**总结：多副本、副本数据与leader同步，不强制刷盘。**

#### （3）Consumer 端：确保消息消费后提交 offset

Consumer 端默认自动向 Kafka 提交 offset，若处理到一半宕机，Offset 已提交，消息丢失！

消费端改为**手动提交 + 先处理后提交，且确保业务处理和提交两个操作是原子性的。**

### （6）Kafka 如何防止数据重复消费

**Kafka 不保证 Exactly-Once，但提供工具让应用实现它。**

重复的根本原因：
- Producer 重试：网络超时，Broker 已写入但未返回 ACK → Producer 重发 → 重复
- 消费者重启：Offset 回退到上一次提交位置 → 重复消费
- 自动提交 Offset：提交后处理失败 → 重启后跳过消息（丢失）；处理中提交 → 重启后重复

#### （1）Producer 幂等性

配置：
~~~ properties
enable.idempotence=true
~~~

原理：每个 Producer 分配唯一 PID（Producer ID），每条消息带 Sequence Number（按 Partition 递增），Broker 维护 (PID, Partition) 的最大 Seq，收到重复 Seq → 直接丢弃。

效果：**单 Partition 内 Exactly-Once（但跨 Partition 不保证）**

#### （2）Consumer 业务幂等

无论 Kafka 是否重复，业务逻辑必须幂等。

- 数据库：落库时，数据使用唯一约束。或者处理后更新这行数据对应的状态，如支付场景，订单状态从 “CREATED” → “PAID”。

- 缓存：Redis 记录已处理 ID；

### （7）Kafka 如何解决消息积压问题

积压 = Latest Offset - Committed Offset 持续增长。

**先定位积压原因**：

- 所有 Partition Lag ：消费者整体处理慢
- 个别 Partition Lag 高：数据倾斜（如某个 key 热点）
- 消费者频繁 Rebalance：GC 停顿、心跳超时

#### （1）方案 1：扩容消费者

前提：Partition 数 ≥ 消费者数，这时扩容消费者，Partition 自动分配给新消费者，并行度提升。

#### （2）优化消费者处理逻辑

- 批量处理
- 异步处理
- 减少外部依赖耗时，如优化数据库查询（走索引）、缓存热点数据

#### （3）临时应急：跳过积压（慎用！）

积压百万条，业务允许丢弃旧数据（重置 Offset 到最新位置），积压消息永久丢失，仅用于非关键业务（如非关键业务数据）。

#### （4）限流与降级（预防积压）

- Producer 限流：使用令牌桶控制发送速率，监控 Broker 磁盘 IO，动态调整。

- Consumer 降级：非核心消息写入死信队列（DLQ），返回错误码，由上游重试。

#### （5）监控与告警

这里需要看一下监控平台是否有 Kafka 堆积的告警，然后ELK日志采集如何知道日志丢失。

参考：https://cloud.tencent.com/developer/article/2088077


## 3、RocketMQ

### （1）RocketMQ 基础
RocketMQ主要由四个基本组件构成：

- NameServer（命名服务器）：
  NameServer是RocketMQ网络中的注册中心和路由中心，提供轻量级服务发现和路由功能。每个Broker启动时都会在所有NameServer上注册自己的路由信息，包括当前Broker的IP地址、提供的Topic等信息。消费者和生产者通过查询NameServer来获取Topic的路由信息。

- Broker（消息代理服务器）：
  Broker是消息处理的核心节点，负责存储消息、验证和服务消息传输。RocketMQ支持多个Broker配置，可以是同步或异步复制数据以确保高可用性。Broker处理大量的数据写入操作，并支持消息的顺序和并行处理。

- Producer（生产者）：
  生产者负责发布消息到指定的Topic。RocketMQ支持多种消息发送模式，包括同步发送、异步发送和单向发送（不等待服务器响应）。

- Consumer（消费者）：
  消费者从Broker订阅消息并处理它们。RocketMQ支持**集群消费和广播消费**两种模式。在集群模式下，同一个Consumer Group中的不同Consumer实例平均分摊消息，而在广播模式下，每个Consumer实例都会接收到所有的消息。

- Topic和Queue： Topic是消息的分类，每个Topic可以分为若干个Queue。RocketMQ通过增加Queue数量来水平扩展Topic的处理能力。

RocketMQ 支持多种消息模式，包括**顺序消息、定时/延时消息和批量消息**等。此外，RocketMQ 提供了丰富的消息过滤功能，消费者可以根据Tag或者SQL92标准进行消息过滤，极大地增加了其灵活性和应用场景。

![alt text](/复习资料/消息队列/img/image-8.png)

Kafka与RocketMQ在设计哲学和优化点上有所不同。**Kafka更注重于处理高吞吐量的数据流，而RocketMQ则提供了更为丰富的消息模式和高级功能，特别适合需要高可靠性和复杂消息处理场景的业务。**

### （2）消息存储机制

#### （1）Kafka的日志存储机制

**日志文件（.log）**： Kafka 所有的消息以日志的形式存储在磁盘上，并且每个Partition都是一个连续的日志文件。

**追加写入**： Kafka采用追加写入的方式存储消息到日志文件中，新消息被添加到文件的末尾，这种方式对于磁盘I/O是非常高效的，因为它大部分是顺序写入，从而极大地提高了写入速度。但是当Partition数量过多时，顺序写就变成了随机写，性能下降。

**索引文件（.index）**： 为了快速查找和读取特定消息，Kafka为每个日志文件维护一个索引文件。索引文件存储消息在日志文件中的偏移量（offset）和其对应在文件中的物理位置，这样可以在不读取整个日志文件的情况下直接跳转到特定的消息。

#### （2）RocketMQ的存储设计

RocketMQ的存储系统主要由以下几部分构成：

**CommitLog**

- **统一存储**： 所有Topic的消息都存储在一个名为CommitLog的文件中，每个消息都有一个全局唯一的偏移量。这种设计简化了消息存储的管理，但也要求高效的索引机制来支持快速消息查找。

- **顺序写入**： 与Kafka类似，RocketMQ的CommitLog也采用顺序写入的方式，以提高写入效率和减少磁盘I/O操作。顺序写入能显著提高消息存储的性能。

- **定期切割**： **RocketMQ定期切分CommitLog和消费队列文件，新的消息写入到新文件中。老旧文件在满足一定条件后可以删除或者归档，以释放存储空间。

- **刷盘策略**： RocketMQ提供了**同步刷盘和异步刷盘**两种策略，用户可以根据业务需求和对性能的要求选择合适的刷盘方式。

**消费队列（Consume Queue）**
- Consume Queue，相当于 Kafka 的 Partition。CQ 是异步构建的（由后台线程从 CommitLog 解析生成），producer 发送消息给 broker，broker 将消息追加到 commitLog，后台线程异步构建 CQ。

- 索引机制：为了快速检索到CommitLog中的消息，RocketMQ为每个队列（Queue）维护一个消费队列（Consume Queue）。**消费队列存储了消息在CommitLog中的偏移量、消息长度和消息标签的哈希码等信息**。CQ 本身不存消息体，只存索引 → 节省空间，加快遍历。

- Consumer 拉取消息时，先读 CQ 获取 offset，再根据 offset 随机读 CommitLog 获取完整消息

**索引文件（Index File）**

- 可选的索引服务：RocketMQ提供了一个独立的索引服务，用于快速检索具有特定键（如ID、Key或是业务属性）的消息。索引文件存储了键到消息物理位置的映射。

- 快速查询：索引文件加速了基于键的消息查询操作，使得RocketMQ能在大数据量中快速定位消息。

- **commitlog 实际存储消息，CQ 提供 offset 帮助定位 commitlog 里面的消息，索引提供根据 key 快速查找消息的能力。**

**文件回收与存储清理**

- RocketMQ通过定期清理旧的CommitLog文件和消费队列文件来回收磁盘空间，这些操作基于消息的存储时间和消费状态。
  
  - 定期删除： 系统根据配置的文件保留策略（如时间间隔、文件大小）自动删除旧文件。
  - 数据压缩： 在必要时，RocketMQ可以对存储的数据进行压缩，以节省存储空间。
  - 支持 同步刷盘 和异步刷盘

### （3）高可用设计

#### （1）Kafka 高可用

- **副本机制和ISR机制**： Kafka通过副本（replicas）机制确保数据的安全性。每个Topic可以被配置为一个或多个分区（partitions），每个分区可以有一个或多个副本。副本分布在不同的Broker上，这样即使一个或多个Broker发生故障，Topic的数据也不会丢失。

- **领导者和追随者**： 每个分区有一个领导者（leader）和多个追随者（followers）。所有的读写请求都由领导者处理，而追随者则从领导者那里复制数据。如果领导者发生故障，系统会从追随者中选举出新的领导者。

- **控制器**（Controller）： 控制器是一个特殊的Broker节点，负责维护领导者的选举和副本状态的管理。如果控制器出现故障，集群中的其他Broker将通过选举产生新的控制器。

- **ZooKeeper协调**： Kafka使用ZooKeeper来管理集群元数据和进行Broker之间的协调，包括领导者选举和集群成员管理。（2.8版本之后该用 kraft，不再依赖 zookeeper）

**总结**：Kafka 里面有 leader + 多个 follower 副本，提供 zookeeper/KRaft 机制来选一个副本作为控制器，管理所有的节点。数据与 leader 保持足够同步的副本称为ISR，只有 ISR 能作为控制器。然后一个 partition 的数据分配到多个副本上，保证数据的可靠性。


#### （2）RocketMQ 高可用

**NameServer的高可用**： RocketMQ使用NameServer管理元数据和路由信息，NameServer采用了无状态设计，多个 NameServer 彼此独立，不通信。Producer/Consumer 启动时配置所有 NameServer 地址列表，客户端轮询或随机选择一个 NameServer 获取路由信息。若某个 NameServer 宕机，客户端自动切换到下一个。即使部分NameServer出现故障，其他NameServer仍能继续提供服务。

**主从架构**： 在Broker级别，RocketMQ采用主从架构，其中主Broker负责处理读写请求，而从Broker则负责复制主Broker的数据（**只读，默认不提供消费服务，仅用于容灾**）。
- 传统主从架构 (Master-Slave) -> 不支持自动切换，Master 挂掉后，Slave 只能提供读服务（消费者可以继续消费 Slave 里的数据），但不能自动升级为 Master，需要人工介入。
- DLedger 模式 (RocketMQ 4.5+ 引入) -> 支持自动切换。一个 Broker 组通常需要 3 个节点（或更多奇数个），它们之间运行 Raft 共识协议。 当 Master 挂掉，剩下的 Slave 会自动进行投票（Leader Election），如果能凑够半数以上的票，就会选出一个新的 Master。

**同步双写与异步复制**： Master 等待 至少一个 Slave 写入成功 才返回 Producer，掉电不丢数据。Master 写入 Page Cache 后立即返回 Producer，Slave 后台拉取数据，掉电可能丢少量数据。
**注意：同步双写 ≠ 强一致：Slave 也是写 Page Cache 就 ACK，不等刷盘！**

**总结**：
- RocketMQ 采用“主从复制（4.5版本之后支持自动故障转移） + 无状态高可用 NameServer”；
- Kafka 采用“多副本 + ISR 共识 + 内置 Controller”。

### （4）消息可靠性

RocketMQ 主要依靠： **单机强持久（Master 同步刷盘） + 主从复制（同步双写）** 来保证消息的可靠性，Kafka 主要依靠：**多副本 ISR + 不依赖刷盘，靠多副本冗余保证整体不丢，而非单机强制刷盘，是异步刷盘**。

### （5）消息重试机制（consumer 消费失败）

- RocketMQ 将重试视为核心功能，内置了完善的、自动的、分级的重试队列机制；
- Kafka 本身不提供重试机制，重试逻辑完全由客户端（Consumer）自行实现。

#### （1）RocketMQ

为每个 Consumer Group 自动创建重试 Topic，当 Consumer 消费失败，RocketMQ 会：
- 将消息投递到一个特殊的重试 Topic
- 自动创建 16 个重试队列（QueueId = 0～15），用于并行重试，消息在重试 Topic 中按延迟等级进行调度
- 当消息重试超过最大次数（默认 16 次），RocketMQ 会将其转入死信 Topic，死信消息不再自动重试，需人工介入处理，保留原始消息内容、Topic、Key 等信息，便于排查

#### （2）Kafka 

Kafka 本身不提供任何重试机制，重试逻辑完全由客户端（Consumer）自行实现。

**异步延迟队列**：消费失败 → 将消息发送到另一个 Kafka Topic（如 retry-topic），retry-topic 的 Consumer 延迟 N 秒后重新处理。可结合时间戳、重试次数头信息实现退避，超过阈值 → 发送到 dlq-topic。

### （6）消息分类

#### （1）顺序消息

RocketMQ：原生强支持。

Producer 使用 MessageQueueSelector 将同一业务 ID（如订单 ID）的消息路由到同一个 Queue，同一个 Queue 内的消息是有序的。Consumer 使用 **单线程 + 串行消费** 保证顺序处理。

Kafka：不直接支持，但可模拟

Kafka Partition 内消息天然有序，Producer 可通过指定 Key（如 orderId）确保相同 Key 的消息进入同一 Partition，Consumer 需单线程消费该 Partition 才能保证处理顺序，若 Consumer 多线程处理同一 Partition → 乱序。

#### （2）延迟消息 / 定时消息

RocketMQ：内置延迟等级机制，支持 18 个固定延迟等级。

Broker 内部有 SCHEDULE_TOPIC_XXXX Topic，包含 18 个 Queue（每个等级一个），消息先写入对应延迟 Queue，后台定时线程扫描，到期后转发到真实 Topic。

Kafka：无内置延迟消息

#### （3）消息过滤

RocketMQ：支持服务端过滤

- Tag 过滤（推荐）
~~~ java
consumer.subscribe("TopicTest", "TagA || TagB");
~~~

Broker 在拉取时直接过滤，只返回匹配 Tag 的消息，高效，减少网络传输。

- SQL 表达式过滤（高级）：
~~~ java
consumer.subscribe("TopicTest", 
    MessageSelector.bySql("a between 0 and 3 and b = 'hello'"));
~~~

Kafka：仅支持客户端过滤，不支持服务端过滤。

#### （4）事务消息

RocketMQ：原生支持分布式事务消息

解决场景：“本地 DB 操作 + 发送消息” 要么都成功，要么都失败。

两阶段提交流程：
- Half Message：Producer 发送“预备消息”到 Broker（对 Consumer 不可见）；
- 执行本地事务（如扣款）；
- 提交/回滚：根据本地事务结果，向 Broker 发送 commit 或 rollback；
- Broker 定时反查：若未收到确认，主动回调 Producer 查询事务状态。

关键保障：即使 Producer 宕机，Broker 也能通过反查机制最终一致；，消息不丢失、不重复（需业务幂等）。

Kafka 的事务是实现 “跨 Partition 写入原子性”，是流处理中的原子写入工具。

### （7）Kafka 和 RocketMQ 的使用场景

Kafka：数据流平台，高吞吐、低延迟、持久化日志管道 + 流处理基础平台。
- 日志收集与聚合（ELK）
- 实时数据管道（MySQL Binlog → Kafka → 实时数仓）
- 流式计算（实时风控、实时推荐）
- 指标监控与告警（Prometheus 指标 → Kafka → 实时告警引擎）

RocketMQ：业务消息引擎，面向复杂业务场景的高可靠、高一致、功能丰富的消息中间件。

- 金融/电商交易系统
- 需要延迟/定时触发的业务
- 消费失败需自动重试
- 对消息可靠性要求极高的场景









